{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 라이브러리 & Cuda 세팅"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchinfo import summary\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchmetrics\n",
    "from torchmetrics.image.fid import FrechetInceptionDistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:1'\n",
    "torch.manual_seed(seed)\n",
    "if device == 'cuda:1':\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "    print(\"using cuda:\", torch.cuda.get_device_name(3))\n",
    "    pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 전처리"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "path_y = 'Untitled Folder/AI_Proj/mask_y'\n",
    "path_n = 'Untitled Folder/AI_Proj/mask_n'\n",
    "image_size = 128\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.CenterCrop(image_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))\n",
    "])\n",
    "\n",
    "data_my = datasets.ImageFolder(path_y, transform = transform)\n",
    "data_mn = datasets.ImageFolder(root = path_n, transform = transform)\n",
    "\n",
    "y = []\n",
    "for img, label in data_my:\n",
    "    y.append(img.numpy())\n",
    "\n",
    "n = []\n",
    "for img, label in data_mn:\n",
    "    n.append(img.numpy())\n",
    "    \n",
    "img_y = torch.Tensor(np.array(y)).to(device)\n",
    "img_n = torch.Tensor(np.array(n)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img_y.shape)\n",
    "print(img_n.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(img_y, img_n)\n",
    "train_size = int(0.8*len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train, test = torch.utils.data.random_split(dataset, [train_size, test_size],generator=torch.Generator(device='cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size= 64\n",
    "dataloader = DataLoader(train, batch_size = batch_size, shuffle=False)\n",
    "dataloader_test = DataLoader(test, batch_size = batch_size, shuffle=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        gen_filt_num = 128\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3,gen_filt_num*2, 4,2,1,bias=False)\n",
    "        self.act1 = nn.LeakyReLU(0.2)\n",
    "        self.conv2 = nn.Conv2d(gen_filt_num*2, gen_filt_num*4, 4,2,1,bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(gen_filt_num * 4)\n",
    "        self.act2 = nn.LeakyReLU(0.2)\n",
    "        self.conv3 = nn.Conv2d(gen_filt_num*4, gen_filt_num * 8, 4, 2, 1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(gen_filt_num * 8)\n",
    "        self.act3 = nn.LeakyReLU(0.2)\n",
    "        \n",
    "        self.conv4 =  nn.Conv2d(gen_filt_num*8, gen_filt_num*8, 3, 1, 1, bias=False)\n",
    "        self.act4 = nn.LeakyReLU(0.2)\n",
    "        self.conv5 = nn.Conv2d(gen_filt_num*8,gen_filt_num*8, 3, 1, 1, bias=False)\n",
    "        self.leaky = nn.LeakyReLU(0.2)\n",
    "        \n",
    "        self.dconv1 = nn.ConvTranspose2d(gen_filt_num*8,gen_filt_num*4, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.dbn1 = nn.BatchNorm2d(gen_filt_num*4)\n",
    "        self.dact1 = nn.ReLU()\n",
    "        self.dconv2 = nn.ConvTranspose2d(gen_filt_num*4,gen_filt_num*2, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.dbn2 = nn.BatchNorm2d(gen_filt_num*2)\n",
    "        self.dact2 = nn.ReLU()\n",
    "        self.dconv3 =  nn.ConvTranspose2d(gen_filt_num*2,gen_filt_num, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.dbn3 =  nn.BatchNorm2d(gen_filt_num)\n",
    "        self.dact3 = nn.ReLU()\n",
    "        self.dconv4 = nn.ConvTranspose2d(gen_filt_num,3, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.dact4 = nn.Tanh()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.act2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.act3(x)\n",
    "        \n",
    "        x = self.conv4(x)\n",
    "        x = self.act4(x)\n",
    "        x = x + self.conv5(x)\n",
    "        x = self.leaky(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.act4(x)\n",
    "        x = x +self.conv5(x)\n",
    "        x = self.leaky(x)\n",
    "        \n",
    "        x = self.dconv1(x)\n",
    "        x = self.dbn1(x)\n",
    "        x = self.dact1(x)\n",
    "        x = self.dconv2(x)\n",
    "        x = self.dbn2(x)\n",
    "        x = self.dact2(x)\n",
    "        x = self.dconv3(x)\n",
    "        x = self.dbn3(x)\n",
    "        x = self.dact3(x)\n",
    "        x = self.dconv4(x)\n",
    "        x = self.dact4(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        dis_filt_num = 128\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, dis_filt_num, 4, 2, 1,bias=False)\n",
    "        self.act1 = nn.LeakyReLU(0.2)\n",
    "        self.conv2 = nn.Conv2d(dis_filt_num, dis_filt_num * 2, 4, 2, 1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(dis_filt_num * 2)\n",
    "        self.act2 = nn.LeakyReLU(0.2)\n",
    "        self.conv3 = nn.Conv2d(dis_filt_num*2, dis_filt_num * 4, 4, 2, 1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(dis_filt_num * 4)\n",
    "        self.act3 = nn.LeakyReLU(0.2)\n",
    "        self.conv4 = nn.Conv2d(dis_filt_num*4, dis_filt_num * 8, 4, 2, 1, bias=False)\n",
    "        self.bn4 = nn.BatchNorm2d(dis_filt_num * 8)\n",
    "        self.act4 = nn.LeakyReLU(0.2)\n",
    "        self.conv5 = nn.Conv2d(dis_filt_num*8, dis_filt_num * 8, 4, 2, 1, bias=False)\n",
    "        self.bn5 = nn.BatchNorm2d(dis_filt_num * 8)\n",
    "        self.act5 = nn.LeakyReLU(0.2)\n",
    "        self.conv6 = nn.Conv2d(dis_filt_num * 8, 1, 4, 1, 0, bias=False)\n",
    "        self.act6 = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.act2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.act3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.bn4(x)\n",
    "        x = self.act4(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.bn5(x)\n",
    "        x = self.act5(x)\n",
    "        x = self.conv6(x)\n",
    "        x = self.act6(x)\n",
    "        \n",
    "        return x.view(-1,1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 훈련"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gen = generator().to(device)\n",
    "dis = discriminator().to(device)\n",
    "\n",
    "loss_fun = nn.BCELoss()\n",
    "from torch import optim\n",
    "\n",
    "optim_g = optim.Adam(gen.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "optim_d = optim.Adam(dis.parameters(), lr=0.0002, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterators = 0\n",
    "epochs = 20\n",
    "loss_hist = {'dis':[], 'gen':[]}\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for x, y in dataloader:\n",
    "\n",
    "        batch_size = x.shape[0]\n",
    "        \n",
    "        y_real = torch.Tensor(batch_size, 1).fill_(1.0).to(device)\n",
    "        y_fake = torch.Tensor(batch_size, 1).fill_(0.0).to(device)\n",
    "        \n",
    "        gen.zero_grad()\n",
    "        out_g = gen(x)\n",
    "        out_d = dis(out_g)\n",
    "        loss_g = loss_fun(out_d, y_real)\n",
    "        loss_g.backward()\n",
    "        optim_g.step()\n",
    "        \n",
    "        dis.zero_grad()\n",
    "        out_d = dis(y)\n",
    "        loss_real = loss_fun(out_d, y_real)\n",
    "        out_d = dis(out_g.detach())\n",
    "        loss_fake = loss_fun(out_d, y_fake)\n",
    "        \n",
    "        loss_d = (loss_real + loss_fake) /2\n",
    "        loss_d.backward()\n",
    "        optim_d.step()\n",
    "        \n",
    "        loss_hist['gen'].append(loss_g.item())\n",
    "        loss_hist['dis'].append(loss_d.item())\n",
    "        \n",
    "        iterators += 1\n",
    "        print('>', end=' ')\n",
    "        \n",
    "        if iterators % 100 == 0:\n",
    "            print('\\n Epoch: %.0f, G_Loss: %.6f, D_Loss: %.6f, time: %.2f min' %(epoch, loss_g.item(), loss_d.item(), (time.time()-start_time)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.title('Loss Progress')\n",
    "plt.plot(loss_hist['gen'])\n",
    "plt.plot(loss_hist['dis'])\n",
    "plt.xlabel('Batch count')\n",
    "plt.ylabel('Loss value')\n",
    "plt.legend(['generator','discriminator'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for x, y in dataloader_test:\n",
    "        mask = x.detach().permute(0,2,3,1).cpu().numpy()\n",
    "        face = y.detach().permute(0,2,3,1).cpu().numpy()\n",
    "        img_fake = gen(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(16):\n",
    "    img = img_fake.detach().permute(0,2,3,1).cpu().numpy()\n",
    "    plt.subplot(4,4,i+1)\n",
    "    plt.imshow(img[i]*0.5 + 0.5)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(16):\n",
    "    plt.subplot(4,4,i+1)\n",
    "    plt.imshow(face[i]*0.5 + 0.5)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 성능 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fid = FrechetInceptionDistance(feature=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.Tensor(img)\n",
    "img = img.type(torch.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img.permute(0,3,1,2)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face = torch.Tensor(face)\n",
    "face = face.type(torch.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face = face.permute(0,3,1,2)\n",
    "face.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fid.update(face, real = True)\n",
    "fid.update(img, real = False)\n",
    "fid.compute()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
